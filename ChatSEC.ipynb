{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from bs4 import BeautifulSoup\n",
        "headers={'User-Agent': 'email@gmail.com'}"
      ],
      "metadata": {
        "id": "GP8QTK7R2c4m"
      },
      "id": "GP8QTK7R2c4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Filings From WRDS (I used DEF14A here. You can change it to include any SEC Filings)"
      ],
      "metadata": {
        "id": "uQ87BCoO2UVW"
      },
      "id": "uQ87BCoO2UVW"
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "from psycopg2.extras import json as psycop_json\n",
        "\n",
        "def get_filing():\n",
        "    with psycopg2.connect(\n",
        "        host=\"wrds-pgdata.wharton.upenn.edu\",\n",
        "        database='wrds',\n",
        "        user='Provide your username',\n",
        "        password='Provide your password',\n",
        "        port=9737\n",
        "    ) as conn:\n",
        "        conn.autocommit = True\n",
        "        with conn.cursor() as cursor:\n",
        "            sql_query = \"\"\"\n",
        "             SELECT\n",
        "                filing_view.form,\n",
        "                filing_view.filing_date,\n",
        "                filing_view.filing,\n",
        "                filing_view.registrants\n",
        "            FROM\n",
        "                wrds_sec_search.filing_view\n",
        "            JOIN\n",
        "                wrds_sec_search.registrant ON registrant.accession = filing_view.accession\n",
        "            WHERE\n",
        "                filing_view.form = 'DEF 14A'\n",
        "            AND\n",
        "                filing_date > '2019-01-01'\n",
        "            \"\"\"\n",
        "            cursor.execute(sql_query)\n",
        "            results = cursor.fetchall()\n",
        "            column_names = [desc[0] for desc in cursor.description]\n",
        "            results=pd.DataFrame(results, columns=column_names)\n",
        "            return results\n",
        "\n",
        "\n",
        "Data=get_filing()\n",
        "\n",
        "Data.registrants=[i[0] for i in Data.registrants]\n",
        "\n",
        "Data = pd.concat([Data, Data['registrants'].apply(pd.Series)], axis=1)"
      ],
      "metadata": {
        "id": "a6VDtcGrTA-i"
      },
      "id": "a6VDtcGrTA-i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keep_compustat_firms(Data):\n",
        "    #get gvkey_cik_link\n",
        "    with psycopg2.connect(\n",
        "        host=\"wrds-pgdata.wharton.upenn.edu\",\n",
        "        database='wrds',\n",
        "        user='Provide your username',\n",
        "        password='Provide your password',\n",
        "        port=9737\n",
        "    ) as conn:\n",
        "        conn.autocommit = True\n",
        "        with conn.cursor() as cursor:\n",
        "            sql_query = \"\"\"\n",
        "            SELECT\n",
        "                *\n",
        "            FROM\n",
        "                wrdssec.wciklink_gvkey\n",
        "            Where\n",
        "                flag in (2,3)\n",
        "            \"\"\"\n",
        "            cursor.execute(sql_query)\n",
        "            results = cursor.fetchall()\n",
        "            column_names = [desc[0] for desc in cursor.description]\n",
        "            link=pd.DataFrame(results, columns=column_names)\n",
        "\n",
        "            link=link.drop_duplicates(subset=['gvkey', 'cik'])\n",
        "\n",
        "            Data=Data[Data['cik'].isin(link['cik'].tolist())].reset_index(drop=True)\n",
        "\n",
        "            return Data\n",
        "\n",
        "Data=keep_compustat_firms(Data)"
      ],
      "metadata": {
        "id": "lUVfVN5hTP-4"
      },
      "id": "lUVfVN5hTP-4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data['cik']=Data.cik.astype(int)\n",
        "Data['cik']=Data.cik.astype(str)\n",
        "Data['accessionstr']=Data['accession'].str.replace(\"-\",\"\")\n",
        "Data['link']='https://www.sec.gov/Archives/edgar/data/'+Data['cik']+ '/'+ Data['accession']+'-index.html'"
      ],
      "metadata": {
        "id": "HyK8h0XQTGhS"
      },
      "id": "HyK8h0XQTGhS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    if not text:\n",
        "        return ''\n",
        "    return re.sub('(\\s+|\\S*@\\S*\\s?|[\\']|[•●\\x92-\\x98])', ' ', text)\n",
        "\n",
        "def get_first_document(doc):\n",
        "    soup = BeautifulSoup(doc, 'html.parser')\n",
        "    documents = soup.find_all(re.compile(\"DOCUMENT\", re.IGNORECASE))\n",
        "\n",
        "    document_texts = []\n",
        "    for document in documents:\n",
        "        text_section = document.find('text')\n",
        "        if text_section:\n",
        "            document_texts.append(clean_text(text_section.text))\n",
        "\n",
        "    return document_texts[0] if document_texts else None\n",
        "\n",
        "Data['text']=Data.filing.progress_apply(lambda x: clean_text(x))"
      ],
      "metadata": {
        "id": "5URi1sEuTEPg"
      },
      "id": "5URi1sEuTEPg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "jBYu40TPTN6L"
      },
      "id": "jBYu40TPTN6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama Setup"
      ],
      "metadata": {
        "id": "jfb8_q0Vgeqp"
      },
      "id": "jfb8_q0Vgeqp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For this section, you will need\n",
        "\n",
        "\n",
        "\n",
        "1.   Access to Llama-2 (https://ai.meta.com/resources/models-and-libraries/llama-downloads/)\n",
        "2.   Access to Huggingace API Key\n",
        "3.   Access to OpenAI API Key (Optional)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XRn6vX6JTkQ3"
      },
      "id": "XRn6vX6JTkQ3"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq  transformers einops accelerate langchain bitsandbytes\n",
        "!pip install -qqq transformers\n",
        "!pip install -qqq llama-index\n",
        "!pip install -qqq sentence_transformers\n",
        "!pip install -qqq ipywidgets==7.7.1"
      ],
      "metadata": {
        "id": "ddJhadGoU6Fj"
      },
      "id": "ddJhadGoU6Fj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers"
      ],
      "metadata": {
        "id": "NauDK0-7PC10"
      },
      "id": "NauDK0-7PC10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "gZCE1eHbyx8B"
      },
      "execution_count": null,
      "outputs": [],
      "id": "gZCE1eHbyx8B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6b34ae",
      "metadata": {
        "id": "fd6b34ae"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms import HuggingFaceLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a849ff",
      "metadata": {
        "id": "85a849ff"
      },
      "outputs": [],
      "source": [
        "from llama_index.prompts.prompts import SimpleInputPrompt\n",
        "\n",
        "system_prompt = \"You are an Finance expert and Q&A assistant. Your goal is to answer questions as accurately as possible based on the instructions and context provided.\"\n",
        "\n",
        "# This will wrap the default prompts that are internal to llama-index\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b2c134",
      "metadata": {
        "id": "26b2c134"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=512,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    tokenizer_kwargs={\"return_token_type_ids\": False},\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed2e83e4",
      "metadata": {
        "id": "ed2e83e4"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import LangchainEmbedding, ServiceContext\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "x1Jeyd2fU8L9"
      },
      "id": "x1Jeyd2fU8L9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Setup"
      ],
      "metadata": {
        "id": "3KLxdCluHHDt"
      },
      "id": "3KLxdCluHHDt"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "bk2iN2nkXkK0"
      },
      "id": "bk2iN2nkXkK0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"sk-\""
      ],
      "metadata": {
        "id": "pYQEzgvkHULp"
      },
      "id": "pYQEzgvkHULp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Pipeline"
      ],
      "metadata": {
        "id": "LUqdnaAohOFc"
      },
      "id": "LUqdnaAohOFc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dce1ec1",
      "metadata": {
        "id": "2dce1ec1"
      },
      "outputs": [],
      "source": [
        "#You need to create a Folder called temp inside MD&A folder.\n",
        "def qa_llama(context):\n",
        "    try:\n",
        "        with open(f'Your Working Folder/temp/temp.txt', 'w') as f:\n",
        "            f.write(context)\n",
        "\n",
        "        # use SimpleDirectoryReader to read the documents\n",
        "        documents = SimpleDirectoryReader('Your Working Folder/temp').load_data()\n",
        "\n",
        "        os.remove(\"Your Working Folder/temp/temp.txt\")\n",
        "\n",
        "        index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "        query_engine = index.as_query_engine()\n",
        "        response = query_engine.query('''As a finance expert, using following text please answer the following question. How many directors are classified as independent director?''')\n",
        "        return response.response\n",
        "    except:\n",
        "        print('error')\n",
        "        return 'error'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def qa_openai(context):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    temperature=0.0,\n",
        "    messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful finance expert.\"},\n",
        "          {\"role\": \"user\", \"content\": ''' \"As a finance expert, using following text please answer the following question. How many directors are classified as independent director?''' '\\n \\n' + context }])\n",
        "    return response[\"choices\"][0][\"message\"]['content']\n",
        "\n",
        "  except:\n",
        "    return('Error. Please check 1) API Key 2)Token Size')"
      ],
      "metadata": {
        "id": "EPfffgthK8FT"
      },
      "id": "EPfffgthK8FT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example using llama\n",
        "print(qa_llama(Data.text[10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrMJvoaJLWYz",
        "outputId": "009d538b-9fd8-4ef6-b9c7-0363887796f0"
      },
      "id": "RrMJvoaJLWYz",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided context information, 5 directors are independent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example using openai\n",
        "print(qa_openai(Data.text[10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHeNY8GFWF5i",
        "outputId": "a08618ce-9d64-43b9-f69c-aa57675ac2e2"
      },
      "id": "WHeNY8GFWF5i",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 5 directors are classified as independent directors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the information for all data\n",
        "Data['output_llama']=Data.text.progress_apply(lambda x: qa_llama(x))"
      ],
      "metadata": {
        "id": "het6BvTNMDuu"
      },
      "id": "het6BvTNMDuu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27fbec07",
      "metadata": {
        "id": "27fbec07"
      },
      "outputs": [],
      "source": [
        "#Save updated data\n",
        "Data.to_excel('updated_data.xlsx')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}